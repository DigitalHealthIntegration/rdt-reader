{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imgaug as ia\n",
    "import keras.backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables.kps import KeypointsOnImage\n",
    "from sklearn.utils import class_weight\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten, Input, Conv2D, multiply, LocallyConnected2D, Lambda, AvgPool2D\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import ReLU, Dense, Conv2D, Flatten,Dropout, MaxPooling2D, GlobalAveragePooling2D, LeakyReLU, Activation, BatchNormalization, Input, merge, Softmax\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import random\n",
    "from keras.constraints import max_norm\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from inspect import signature\n",
    "from sklearn.metrics import average_precision_score,mean_squared_error\n",
    "from keras.applications.inception_v3 import InceptionV3,preprocess_input\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "def loadData(noBatchSamples,batchIdx,testData=\"test_data.txt\",rootPathCentreLabel=\"./obj/labels\",rootPathCroppedImages = \"./obj/images\"):\n",
    "    \"\"\"This function loads data from the directory of labels, it works with the yolo data format.\n",
    "        \n",
    "        Args:\n",
    "\n",
    "            noBatchSamples (int) : Number of samples per batch\n",
    "            batchIdx (int) : Batch number\n",
    "            duplicativeFactor (int) : Number of times to oversample rare date\n",
    "            rareData (str) : Filenames of rare data samples\n",
    "            rootPathCentreLabel (str) : Directory with labels in yolo format\n",
    "            rootPathCroppedImages (str) : Directory with images, image name and label name should be same eg: 1.jpg 1.txt\n",
    "        \n",
    "        Returns:\n",
    "            list: Images in list \n",
    "            list: Targets \n",
    "            list: File names\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    y_train=[]\n",
    "    X_train=[]\n",
    "    name=[]\n",
    "    f = open(testData)\n",
    "    lines = f.readlines()\n",
    "    lines = [x.strip() for x in lines]\n",
    "    f.close()\n",
    "    for ind,element in enumerate(os.listdir(rootPathCentreLabel)):\n",
    "        if  ind >= noBatchSamples*batchIdx and ind<=noBatchSamples*(batchIdx+1):\n",
    "            with open(os.path.join(rootPathCentreLabel,element)) as fin:\n",
    "                y = [(0,0),(0,0)]\n",
    "#                 print(os.path.join(rootPathCroppedImages,element.replace(\".txt\",\".jpg\")))\n",
    "                img = cv2.imread(os.path.join(rootPathCroppedImages,element.replace(\".txt\",\".jpg\")),cv2.IMREAD_COLOR)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                for line in fin:\n",
    "                    line=line.split(\" \")\n",
    "                    if line[0]==\"0\" :\n",
    "                        pixel_y_pos =int(float(line[2]))\n",
    "                        y[0]=(int(float(line[1])*100),int(float(line[2])*2000))\n",
    "                    elif line[0]==\"1\" :\n",
    "                        pixel_y_pos =int(float(line[2]))\n",
    "                        if float(line[2])<1:\n",
    "                            y[1]=(int(float(line[1])*100),int(float(line[2])*2000))\n",
    "                    elif line[0]==\"2\" :\n",
    "                        pixel_y_pos =int(float(line[2]))\n",
    "                        if float(line[2])<1:\n",
    "                            y[1]=(int(float(line[1])*100),int(float(line[2])*2000))\n",
    "            if element in lines:\n",
    "                y_train.append(y)\n",
    "                X_train.append(img)\n",
    "                name.append(element)\n",
    "            else:\n",
    "                pass\n",
    "    combined = list(zip(X_train, y_train,name))\n",
    "    random.Random(23).shuffle(combined)\n",
    "\n",
    "    X_train[:], y_train[:],name[:] = zip(*combined)\n",
    "    X_train=np.array(X_train)  \n",
    "    print(len(X_train))\n",
    "    return X_train,y_train,name #np.zeros((128, 32, 32, 3), dtype=np.uint8) + (batch_idx % 255)\n",
    "\n",
    "\n",
    "def key2Target(keypoints,name):\n",
    "    \"\"\"This function converts keypoints returned after data augmentation to numpy arrays.\n",
    "        \n",
    "        Args:\n",
    "\n",
    "            keypoints (imgaug.augmentables.kps.KeypointsOnImage) : Keypoints on the image\n",
    "            name (list) : File names\n",
    "        \n",
    "        Returns:\n",
    "            list: Images in list \n",
    "            list: Targets \n",
    "            list: File names\n",
    "\n",
    "    \"\"\"\n",
    "    numred=0\n",
    "    y_test_regression=[]\n",
    "    y_test_categorical = []\n",
    "    for i,k in enumerate(keypoints):\n",
    "        y=np.zeros((2))\n",
    "        y_class=np.zeros((2))\n",
    "        \n",
    "        if k[0][1]<=700 and (k[1][1]<=700 or k[1][1]>=1800): # Red line:False && Blue line:False\n",
    "            y[0]=0\n",
    "            y[1]=0\n",
    "            y_class[0]=0\n",
    "            y_class[1]=0\n",
    "        \n",
    "        elif k[0][1]>=700 and (k[1][1]<=700 or k[1][1]>=1800): # Red line:False && Blue line:True\n",
    "            y[0]=k[0][1]/2000\n",
    "            y[1]=0\n",
    "            y_class[0]=1\n",
    "            y_class[1]=0\n",
    "        elif (k[1][1]>=700 and k[1][1]<=1900) and k[0][1]>=700: # Red line:True && Blue line:True\n",
    "            numred+=1\n",
    "            y[0]=k[0][1]/2000\n",
    "            y[1]=k[1][1]/2000\n",
    "            y_class[0]=1\n",
    "            y_class[1]=1\n",
    "        y_test_regression.append(np.array(y))\n",
    "        y_test_categorical.append(np.array(y_class))\n",
    "    return np.array(y_test_regression),np.array(y_test_categorical)\n",
    "\n",
    "\n",
    "def returnAugmentationObj(percentageOfChance=0.):\n",
    "    \"\"\"This function returns an augementation pipeline which can be used to augment training data.\n",
    "        \n",
    "        Args:\n",
    "            percentageOfChance (float) : Percentage of chance , eg: if it is 0.5, 50% of the images will go through the pipeline\n",
    "        \n",
    "        Returns:\n",
    "            :class:`imgaug.augmenters.meta.Sequential` : Image augmentor \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    sometimes = lambda aug: iaa.Sometimes(percentageOfChance, aug)\n",
    "\n",
    "    # Define our sequence of augmentation steps that will be applied to every image\n",
    "    # All augmenters with per_channel=0.5 will sample one value _per image_\n",
    "    # in 50% of all cases. In all other cases they will sample new values\n",
    "    # _per channel_.\n",
    "    seq = iaa.Sequential(\n",
    "        [\n",
    "            sometimes(iaa.Affine(\n",
    "                translate_percent={\"x\": (-0.05, 0.05), \"y\": (-0.03, 0.03)} # translate by -x to +x percent (per axis)\n",
    "            ))\n",
    "           \n",
    "        ])\n",
    "    return seq\n",
    "\n",
    "\n",
    "def lossReg(y_true,y_pred):\n",
    "    \"\"\"Custom loss function to penalize A type virus versus B type written for keras.\n",
    "    \"\"\"\n",
    "    mask=K.ones_like(y_true)\n",
    "    l=K.square(y_pred-y_true)\n",
    "    penalty = tf.constant([10.0])\n",
    "    mask =tf.add(penalty,tf.to_float (tf.math.logical_or(tf.math.logical_and(tf.math.greater(y_true[:,0],y_true[:,1]),tf.math.less(y_pred[:,0],y_pred[:,1])),tf.math.logical_and(tf.math.less(y_true[:,0],y_true[:,1]),tf.math.greater(y_pred[:,0],y_pred[:,1])))))\n",
    "    mask = tf.stack([K.ones_like(y_true[:,0]),mask],axis=1)\n",
    "    return K.mean(tf.math.multiply(l,mask),axis=-1)\n",
    "\n",
    "\n",
    "def returnModel(loadWeights,weightsFile=\"./red_blue_cust.hdf5\"):\n",
    "    \"\"\"This function returns a keras model.\n",
    "        \n",
    "        Args:\n",
    "            loadWeights (bool) : Load weights specified in the weightsFile param\n",
    "            weightsFile (str) : Path to weights\n",
    "        \n",
    "        Returns:\n",
    "            :class:`keras.model.Model` : Neural Network \n",
    "\n",
    "    \"\"\"\n",
    "    x = Input(shape=(500, 100,3))\n",
    "\n",
    "    conv1=Conv2D(8, (3,3), padding='valid')(x)\n",
    "    batchnorm1 = BatchNormalization()(conv1)\n",
    "    act1 = ReLU()(batchnorm1)\n",
    "    \n",
    "\n",
    "    conv2=Conv2D(8, (3,3), padding='valid')(act1)\n",
    "    batchnorm2 = BatchNormalization()(conv2)\n",
    "    act2 = ReLU()(batchnorm2)\n",
    "    maxpool2 = MaxPooling2D((2,2))(act2)\n",
    "\n",
    "    conv3=Conv2D(16, (3,3), padding='valid')(maxpool2)\n",
    "    batchnorm3 = BatchNormalization()(conv3)\n",
    "    act3 = ReLU()(batchnorm3)\n",
    "\n",
    "    conv4=Conv2D(16, (3,3), padding='valid')(act3)\n",
    "    batchnorm4 = BatchNormalization()(conv4)\n",
    "    act4 = ReLU()(batchnorm4)\n",
    "    maxpool3 = MaxPooling2D((2,2))(act4)\n",
    "\n",
    "    flat1 = Flatten()(maxpool3)\n",
    "    D1 = Dense(256)(flat1)\n",
    "    batchnorm5 = BatchNormalization()(D1)\n",
    "    act5 = ReLU()(batchnorm5)\n",
    "\n",
    "    D2 = Dense(128,kernel_constraint=max_norm(2))(act5)\n",
    "    batchnorm6 = BatchNormalization()(D2)\n",
    "    act6 = ReLU()(batchnorm6)\n",
    "\n",
    "\n",
    "    D_soft = Dense(2)(act6)\n",
    "    batchnorm7 = BatchNormalization()(D_soft)\n",
    "    out1 = Activation('sigmoid',name=\"cat_kash\")(batchnorm7)\n",
    "\n",
    "    D_sigmoid = Dense(2)(act6)\n",
    "    batchnorm8 = BatchNormalization()(D_sigmoid)\n",
    "    out2 = Activation('sigmoid',name=\"reg_kash\")(batchnorm8)\n",
    "\n",
    "    model = Model(inputs=x, outputs=[out1,out2])\n",
    "    if (loadWeights):\n",
    "        model.load_weights(weightsFile,by_name=True)\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "    \n",
    "\n",
    "def modelTransferLearning(loadWeights,weightsFile=\"./red_blue_transf.hdf5\"):\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    D1 = Dense(256)(x)\n",
    "    batchnorm5 = BatchNormalization()(D1)\n",
    "    act5 = ReLU()(batchnorm5)\n",
    "    D2 = Dense(128)(act5)\n",
    "    batchnorm6 = BatchNormalization()(D2)\n",
    "    act6 = ReLU()(batchnorm6) \n",
    "    D_soft = Dense(2)(act6)\n",
    "    batchnorm7 = BatchNormalization()(D_soft)\n",
    "    out1 = Activation('sigmoid',name=\"cat_kash\")(batchnorm7)\n",
    "\n",
    "    D_sigmoid = Dense(2)(act6)\n",
    "    batchnorm8 = BatchNormalization()(D_sigmoid)\n",
    "    out2 = Activation('sigmoid',name=\"reg_kash\")(batchnorm8)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=[out1,out2])\n",
    "    for layer in model.layers[:249]:\n",
    "       layer.trainable = False\n",
    "    for layer in model.layers[249:]:\n",
    "       layer.trainable = True\n",
    "#     model.summary()\n",
    "    if (loadWeights):\n",
    "        model.load_weights(weightsFile,by_name=True)\n",
    "    return model\n",
    "\n",
    "\n",
    "config = tf.ConfigProto( device_count = {'GPU': 0 , 'CPU': 4} ) # Correctly put number of GPU and CPU\n",
    "sess = tf.Session(config=config) \n",
    "with sess:\n",
    "    useTransferLearning = False\n",
    "    SeqAug = returnAugmentationObj()\n",
    "    print(\"loading model...\")\n",
    "    if useTransferLearning:\n",
    "        model = modelTransferLearning(True,\"red_blue_transf.hdf5\")\n",
    "    else:\n",
    "        model = returnModel(True,\"red_blue_cust.hdf5\")\n",
    "\n",
    "    filepath=\"weights-latest_model_YCrCb_test.hdf5\" # Name and path of weights to save\n",
    "\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min') # Checkpoint call back to save best model on validation set\n",
    "\n",
    "    lrd=ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=10, verbose=1, mode='auto', min_delta=0.00001, cooldown=5, min_lr=0.00000000000000000001) # Callback to control learning rate on plateau condition \n",
    "    print(\"loading data...\")\n",
    "    X_train,y_train,names = loadData(650,0) # Load all data in one batch, 3 since sample data has only 3\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0., random_state=42) # Split data into training and testing \n",
    "\n",
    "    callbacks_list = [checkpoint,lrd]\n",
    "\n",
    "    optimizer = Adam(lr=0.0009, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True) # Optimizer used to train\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss={\"cat_kash\":\"binary_crossentropy\",\"reg_kash\":lossReg}, metrics={\"cat_kash\":'accuracy',\"reg_kash\":\"mse\"}) # Compile model for training\n",
    "    K.set_learning_phase(0)\n",
    "\n",
    "\n",
    "    xx_tr=[]\n",
    "    yy_reg_tr=[]\n",
    "    yy_cat_tr=[]\n",
    "    images_aug_tr, keypoints_aug_tr = SeqAug(images=X_train,keypoints=y_train)  \n",
    "    tar_train_reg,tar_train_cat=key2Target(keypoints_aug_tr,names)\n",
    "    for ind,im in enumerate(images_aug_tr):\n",
    "        im=im[1000:1500,:,:] # Crop out only test area\n",
    "        if(useTransferLearning):\n",
    "            xx_tr.append(preprocess_input(im))\n",
    "        else:\n",
    "            im = im/255.0\n",
    "            im = np.array(im,dtype=np.float32)\n",
    "            yuv_im = cv2.cvtColor(im, cv2.COLOR_RGB2YCrCb)\n",
    "            xx_tr.append(yuv_im)\n",
    "    for ii in tar_train_reg:\n",
    "        yy_reg_tr.append(ii)\n",
    "    for ind,ii in enumerate(tar_train_cat):\n",
    "        if False: # Set to true to save train images augmentated\n",
    "            images_aug_tr[ind] = cv2.putText(images_aug_tr[ind],str(tar_train_cat[ind]),(0,20), font, 0.5,(255,0,0),2,cv2.LINE_AA)\n",
    "            images_aug_tr[ind] = cv2.circle(images_aug_tr[ind],(50,int(keypoints_aug_tr[ind][0][1])),5, (0,0,255), 5)\n",
    "            try:\n",
    "                images_aug_tr[ind] = cv2.circle(images_aug_tr[ind],(50,int(keypoints_aug_tr[ind][1][1])),5, (255,0,0), 5)\n",
    "            except:\n",
    "                pass\n",
    "            images_aug_tr[ind] = cv2.cvtColor(images_aug_tr[ind], cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            cv2.imwrite(\"./sample/train/\"+str(ind)+\".jpg\",images_aug_tr[ind][1000:1500,:,:])\n",
    "        yy_cat_tr.append(ii)\n",
    "    xxx=np.array(xx_tr)\n",
    "    yyy_reg=np.array(yy_reg_tr)\n",
    "    yyy_cat=np.array(yy_cat_tr)\n",
    "    predictions=model.predict(xxx)\n",
    "    y_test = yyy_cat[:,0]\n",
    "    y_score = predictions[0][:,0]\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_score)\n",
    "    average_precision1 = average_precision_score(y_test, y_score)\n",
    "\n",
    "    # In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\n",
    "    step_kwargs = ({'step': 'post'}\n",
    "                   if 'step' in signature(plt.fill_between).parameters\n",
    "                   else {})\n",
    "    plt.step(recall, precision, color='b', alpha=0.2,\n",
    "             where='post',label=\"Blue line\")\n",
    "    plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    \n",
    "    \n",
    "    y_test = yyy_cat[:,1]\n",
    "    y_score = predictions[0][:,1]\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_score)\n",
    "    average_precision2 = average_precision_score(y_test, y_score)\n",
    "\n",
    "    # In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\n",
    "    step_kwargs = ({'step': 'post'}\n",
    "                   if 'step' in signature(plt.fill_between).parameters\n",
    "                   else {})\n",
    "    plt.step(recall, precision, color='r', alpha=0.2,\n",
    "             where='post',label=\"Red line\")\n",
    "    plt.fill_between(recall, precision, alpha=0.2, color='r', **step_kwargs)\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    print(average_precision2)\n",
    "    plt.title('2-class Precision-Recall curve: AP for blue={0:0.2f} AP for red={1:0.2f}'.format(\n",
    "              average_precision1,average_precision2))\n",
    "    plt.legend()\n",
    "    print(\"Mean squared Error:\",mean_squared_error(yyy_reg, predictions[1]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.0189923\n",
    "0.024536721439542924"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(name),len(predictions[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ims_path=\"./obj/images\"\n",
    "label_path=\"./obj/labels\"\n",
    "label_path=\"./obj/labels\"\n",
    "\n",
    "for index,name in enumerate(names):\n",
    "    basename = name.replace(\".txt\",\"\")\n",
    "    \n",
    "    try:\n",
    "        img_path = os.path.join(ims_path,basename+\".jpg\")\n",
    "        img = cv2.imread(img_path)\n",
    "        img[0]\n",
    "    except:\n",
    "        img_path = os.path.join(ims_path,basename+\".jpeg\")\n",
    "        img = cv2.imread(img_path)\n",
    "        img[0]\n",
    "#     img = cv2.putText(images_aug_te[ind],str(tar_test_cat[ind]),(0,20), font, 0.5,(255,0,0),2,cv2.LINE_AA)\n",
    "    if predictions[0][index,0]>0.5:\n",
    "        img = cv2.circle(img,(50,int(predictions[1][index,0]*2000)),5, (255,0,0), 5)\n",
    "    if predictions[0][index,1]>0.5:\n",
    "        img = cv2.circle(img,(50,int(predictions[1][index,1]*2000)),5, (0,0,255), 5)\n",
    "    cv2.imwrite(\"./sample/test/\"+basename+\".jpg\",img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flasker\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0923 17:23:58.727431  9904 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0923 17:24:09.126708  9904 deprecation.py:323] From D:\\source\\repos\\rdt-reader\\conda_env\\tf_gpu\\lib\\site-packages\\tensorflow\\contrib\\predictor\\saved_model_predictor.py:153: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "W0923 17:24:11.897046  9904 deprecation.py:323] From D:\\source\\repos\\rdt-reader\\conda_env\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    }
   ],
   "source": [
    "servObj = flasker.FluServer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"D:/source/repos/audere/new_images_sarvesh/FluA/Morning/IMG_1578.jpg\")\n",
    "\n",
    "flasker.runPipeline(img,servObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/source/repos/audere/new_images_sarvesh\\FluA\\Morning\\IMG_1578.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA\\Morning\\IMG_1580.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA\\Morning\\IMG_1581.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA\\Morning\\IMG_1582.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA\\Morning\\IMG_1583.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA\\Morning\\IMG_1584.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA\\Morning\\IMG_1585.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA\\Morning\\IMG_1586.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA\\Morning\\IMG_1587.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA\\Morning\\IMG_1588.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA\\Morning\\IMG_1589.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA\\Morning\\IMG_1590.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA\\Morning\\IMG_1591.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA\\Morning\\IMG_1592.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA\\Morning\\IMG_1593.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA\\Morning\\IMG_1594.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA\\Morning\\IMG_1595.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA\\Morning\\IMG_1596.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA\\Morning\\IMG_1597.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA\\Morning\\IMG_1598.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA\\Morning\\IMG_1599.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA\\Morning\\IMG_1600.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA\\Morning\\IMG_1601.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA\\Morning\\IMG_1602.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA\\Morning\\IMG_1603.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA\\Morning\\IMG_1604.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA\\Morning\\IMG_1605.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA\\Morning\\IMG_1606.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA\\Morning\\IMG_1607.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA\\Morning\\IMG_1608.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA\\Morning\\IMG_1609.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA\\Morning\\IMG_1610.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA\\Morning\\IMG_1611.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA\\Morning\\IMG_1612.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA\\Morning\\IMG_1613.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA\\Morning\\IMG_1614.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA\\Morning\\IMG_1615.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA\\Morning\\IMG_1616.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA+B\\Morning\\IMG_1527.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA+B\\Morning\\IMG_1528.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA+B\\Morning\\IMG_1529.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA+B\\Morning\\IMG_1531.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA+B\\Morning\\IMG_1532.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA+B\\Morning\\IMG_1533.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA+B\\Morning\\IMG_1534.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA+B\\Morning\\IMG_1535.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA+B\\Morning\\IMG_1536.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA+B\\Morning\\IMG_1537.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA+B\\Morning\\IMG_1538.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA+B\\Morning\\IMG_1539.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA+B\\Morning\\IMG_1540.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA+B\\Morning\\IMG_1541.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA+B\\Morning\\IMG_1542.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA+B\\Morning\\IMG_1543.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA+B\\Morning\\IMG_1544.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA+B\\Morning\\IMG_1545.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA+B\\Morning\\IMG_1546.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA+B\\Morning\\IMG_1547.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA+B\\Morning\\IMG_1548.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA+B\\Morning\\IMG_1549.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA+B\\Morning\\IMG_1550.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA+B\\Morning\\IMG_1551.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA+B\\Morning\\IMG_1552.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA+B\\Morning\\IMG_1553.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA+B\\Morning\\IMG_1554.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA+B\\Morning\\IMG_1555.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA+B\\Morning\\IMG_1556.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA+B\\Morning\\IMG_1557.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluA+B\\Morning\\IMG_1558.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluB\\Morning\\IMG_1495.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluB\\Morning\\IMG_1496.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluB\\Morning\\IMG_1497 2.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluB\\Morning\\IMG_1497.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluB\\Morning\\IMG_1498.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluB\\Morning\\IMG_1502.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluB\\Morning\\IMG_1503.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluB\\Morning\\IMG_1504.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluB\\Morning\\IMG_1505.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluB\\Morning\\IMG_1506.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluB\\Morning\\IMG_1507.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluB\\Morning\\IMG_1508.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluB\\Morning\\IMG_1509.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluB\\Morning\\IMG_1510.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluB\\Morning\\IMG_1511.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluB\\Morning\\IMG_1512.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluB\\Morning\\IMG_1513.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluB\\Morning\\IMG_1514.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluB\\Morning\\IMG_1515.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluB\\Morning\\IMG_1516.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluB\\Morning\\IMG_1517.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluB\\Morning\\IMG_1518.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluB\\Morning\\IMG_1519.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluB\\Morning\\IMG_1520.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluB\\Morning\\IMG_1521.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluB\\Morning\\IMG_1522.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluB\\Morning\\IMG_1523.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluB\\Morning\\IMG_1524.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluB\\Morning\\IMG_1525.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\FluB\\Morning\\IMG_1526.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\Negative\\Morning\\IMG_1559.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\Negative\\Morning\\IMG_1560.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\Negative\\Morning\\IMG_1561.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\Negative\\Morning\\IMG_1562.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\Negative\\Morning\\IMG_1563.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\Negative\\Morning\\IMG_1564.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\Negative\\Morning\\IMG_1565.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\Negative\\Morning\\IMG_1566.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\Negative\\Morning\\IMG_1567.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\Negative\\Morning\\IMG_1568.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\Negative\\Morning\\IMG_1569.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\Negative\\Morning\\IMG_1570.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\Negative\\Morning\\IMG_1571.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\Negative\\Morning\\IMG_1572.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\Negative\\Morning\\IMG_1573.jpg\n",
      "D:/source/repos/audere/new_images_sarvesh\\Negative\\Morning\\IMG_1574.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0923 17:29:10.252678  9904 ultratb.py:155] Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "root_dir = \"D:/source/repos/audere/new_images_sarvesh/\"\n",
    "y_truth =[]\n",
    "y_pred = []\n",
    "failed_images = []\n",
    "for filename in glob.iglob(root_dir + '**/*.jpg', recursive=True):\n",
    "    img = cv2.imread(filename)\n",
    "    tmp_pred=flasker.runPipeline(img,servObj)\n",
    "    y_pred.append(tmp_pred)\n",
    "    if \"Negative\" in filename:\n",
    "        y_truth.append(0)\n",
    "        if tmp_pred != 0:\n",
    "            failed_images.append(filename)\n",
    "    elif \"FluA+B\" in filename:\n",
    "        y_truth.append(3)\n",
    "        if tmp_pred != 3:\n",
    "            failed_images.append(filename)\n",
    "\n",
    "    elif \"FluA\" in filename:\n",
    "        y_truth.append(1)\n",
    "        if tmp_pred != 1:\n",
    "            failed_images.append(filename)\n",
    "\n",
    "    elif \"FluB\" in filename:\n",
    "        y_truth.append(2)\n",
    "        if tmp_pred != 2:\n",
    "            failed_images.append(filename)\n",
    "\n",
    "        \n",
    "    print(filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'faile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-779ac052948b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfaile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'faile' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
